{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Mathematical building blocks of NNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.3\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import  layers\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A first look at a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type(train_images) = <class 'numpy.ndarray'>\n",
      "train_images.shape = (60000, 28, 28)\n",
      "type(train_labels) = <class 'numpy.ndarray'>\n",
      "train_labels.shape = (60000,)\n",
      "train_labels = array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)\n",
      "\n",
      "type(test_images) = <class 'numpy.ndarray'>\n",
      "test_images.shape = (10000, 28, 28)\n",
      "type(test_labels) = <class 'numpy.ndarray'>\n",
      "test_labels.shape = (10000,)\n",
      "test_labels = array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{type(train_images) = }\")\n",
    "print(f\"{train_images.shape = }\")\n",
    "print(f\"{type(train_labels) = }\")\n",
    "print(f\"{train_labels.shape = }\")\n",
    "print(f\"{train_labels = }\")\n",
    "print(\"\")\n",
    "print(f\"{type(test_images) = }\")\n",
    "print(f\"{test_images.shape = }\")\n",
    "print(f\"{type(test_labels) = }\")\n",
    "print(f\"{test_labels.shape = }\")\n",
    "print(f\"{test_labels = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define NN\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prep\n",
    "train_images = train_images.reshape((-1, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "test_images = test_images.reshape((-1, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 5s 9ms/step - loss: 0.2526 - accuracy: 0.9271\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.1026 - accuracy: 0.9688\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0667 - accuracy: 0.9797\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0481 - accuracy: 0.9851\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 4s 8ms/step - loss: 0.0367 - accuracy: 0.9887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb4647f2c40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_digits = test_images[0:8]\n",
    "predictions = model.predict(test_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_clss = predictions.argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i in range(8):\n",
    "    img = test_digits[i]\n",
    "    pred = predicted_clss[i]\n",
    "\n",
    "    ax = fig.add_subplot(2, 4, i + 1)\n",
    "    ax.imshow(img.reshape(28,28))\n",
    "    ax.title.set_text(f\"{pred = }\")\n",
    "    ax.set_axis_off()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0689 - accuracy: 0.9785\n",
      "test_acc = 0.9785\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"{test_acc = :.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining derivates: The backprop algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_of_y_wrt_x = <tf.Tensor: shape=(), dtype=float32, numpy=2.0>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(0.)\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "print(f\"{grad_of_y_wrt_x = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_of_y_wrt_x = <tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[2., 2.],\n",
      "       [2., 2.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(tf.random.uniform((2, 2)))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = 2 * x + 3\n",
    "\n",
    "grad_of_y_wrt_x = tape.gradient(y, x)\n",
    "print(f\"{grad_of_y_wrt_x = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_of_y_wrt_W_and_b = [<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
      "array([[0.3804127, 0.3804127],\n",
      "       [1.2618934, 1.2618934]], dtype=float32)>, <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.random.uniform((2, 2)))\n",
    "b = tf.Variable(tf.zeros((2,)))\n",
    "x = tf.random.uniform((2, 2))\n",
    "\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    y = tf.matmul(x, W) + b\n",
    "\n",
    "grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])\n",
    "print(f\"{grad_of_y_wrt_W_and_b = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reimplementing out first example from scratch in TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = activation( dot(input, W) + b)\n",
    "\n",
    "class NaiveDense:\n",
    "    def __init__(self, input_size, output_size, activation):\n",
    "        self.activation = activation\n",
    "\n",
    "        w_shape = (input_size, output_size)\n",
    "        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)\n",
    "        self.W = tf.Variable(w_initial_value)\n",
    "\n",
    "        b_shape = (output_size,)\n",
    "        b_initial_value = tf.zeros(b_shape)\n",
    "        self.b = tf.Variable(b_initial_value)\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        return self.activation(tf.matmul(inputs, self.W) + self.b)\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [self.W, self.b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_dense():\n",
    "    l = NaiveDense(10, 20, tf.nn.relu)\n",
    "\n",
    "    random_input = tf.random.uniform((128, 10))\n",
    "\n",
    "    l_out = l(random_input)\n",
    "\n",
    "    w, b = l.weights\n",
    "    expected_output = tf.maximum(random_input @ w + b, 0)\n",
    "\n",
    "    assert (l_out == expected_output).numpy().all()\n",
    "\n",
    "test_naive_dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveSequential:\n",
    "    def __init__(self, layers):\n",
    "        self.layers = layers\n",
    "\n",
    "    def __call__(self, inputs):\n",
    "        x = inputs\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    @property\n",
    "    def weights(self):\n",
    "        return [w for layer in self.layers for w in layer.weights]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_naive_sequential():\n",
    "    ls = NaiveSequential(\n",
    "        [\n",
    "            NaiveDense(10, 20, tf.nn.relu),\n",
    "            NaiveDense(20, 5, tf.nn.relu),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    random_input = tf.random.uniform((128, 10))\n",
    "\n",
    "    ls_out = ls(random_input)\n",
    "\n",
    "    w1, b1, w2, b2 = ls.weights\n",
    "\n",
    "    x1 = tf.maximum(random_input @ w1 + b1, 0)\n",
    "    expected_output = tf.maximum(x1 @ w2 + b2, 0)\n",
    "\n",
    "    assert (ls_out == expected_output).numpy().all()\n",
    "\n",
    "test_naive_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_generator(images, labels, batch_size=128):\n",
    "        assert len(images) == len(labels)\n",
    "\n",
    "        for index in range(0, len(images), batch_size):\n",
    "            batch_images = images[index: index + batch_size]\n",
    "            batch_labels = labels[index: index + batch_size]\n",
    "            yield batch_images, batch_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_i = array([0, 1, 2])\n",
      "batch_l = array([0, 1, 2])\n",
      "\n",
      "batch_i = array([3, 4, 5])\n",
      "batch_l = array([3, 4, 5])\n",
      "\n",
      "batch_i = array([6, 7, 8])\n",
      "batch_l = array([6, 7, 8])\n",
      "\n",
      "batch_i = array([ 9, 10])\n",
      "batch_l = array([ 9, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_batch_generator():\n",
    "    batch_gen = get_batch_generator(np.arange(11), np.arange(11), batch_size=3)\n",
    "\n",
    "    for batch_i, batch_l in batch_gen:\n",
    "        print(f\"{batch_i = }\")\n",
    "        print(f\"{batch_l = }\")\n",
    "        print(\"\")\n",
    "\n",
    "test_batch_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3\n",
    "\n",
    "def update_weights(gradients, weights):\n",
    "    \"\"\"plain SGD step\"\"\"\n",
    "    for g, w in zip(gradients, weights):\n",
    "        w.assign_sub(g * LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_update_weights():\n",
    "    # get random model\n",
    "    model = NaiveSequential(\n",
    "        [\n",
    "            NaiveDense(10, 20, tf.nn.relu),\n",
    "            NaiveDense(20, 5, tf.nn.relu),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # get random input and targets\n",
    "    random_input = tf.random.uniform((128, 10))\n",
    "    random_target = tf.random.uniform((128, 5))\n",
    "    loss_f = tf.keras.losses.mean_squared_error\n",
    "\n",
    "    # forward pass and compute gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(random_input)\n",
    "        per_sample_losses = loss_f(random_target, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "\n",
    "    # optimizer step\n",
    "    update_weights(gradients, model.weights)\n",
    "\n",
    "    # check loss improves\n",
    "    new_predictions = model(random_input)\n",
    "    new_per_sample_losses = loss_f(random_target, new_predictions)\n",
    "    new_average_loss = tf.reduce_mean(new_per_sample_losses)\n",
    "\n",
    "    assert new_average_loss < average_loss\n",
    "\n",
    "\n",
    "test_update_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_step(model, batch_images, batch_labels, loss_f):\n",
    "    # forward pass and compute gradients\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(batch_images)\n",
    "        per_sample_losses = loss_f(batch_labels, predictions)\n",
    "        average_loss = tf.reduce_mean(per_sample_losses)\n",
    "\n",
    "    gradients = tape.gradient(average_loss, model.weights)\n",
    "    update_weights(gradients, model.weights)\n",
    "\n",
    "    return average_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_training_step():\n",
    "    # get random model\n",
    "    model = NaiveSequential(\n",
    "        [\n",
    "            NaiveDense(10, 20, tf.nn.relu),\n",
    "            NaiveDense(20, 5, tf.nn.relu),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # get random input and targets\n",
    "    random_input = tf.random.uniform((128, 10))\n",
    "    random_target = tf.random.uniform((128, 5))\n",
    "    loss_f = tf.keras.losses.mean_squared_error\n",
    "\n",
    "    # training step\n",
    "    loss = training_step(model, random_input, random_target, loss_f)\n",
    "    for _ in range(10):\n",
    "        new_loss = training_step(model, random_input, random_target, loss_f)\n",
    "\n",
    "        # check loss improves\n",
    "        assert new_loss < loss\n",
    "\n",
    "\n",
    "test_training_step()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, images, labels, *, epochs, loss_f, batch_size=128):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"{epoch = }\")\n",
    "        batch_generator = get_batch_generator(images, labels)\n",
    "\n",
    "        for batch_i, (batch_images, batch_labels) in enumerate(batch_generator):\n",
    "            loss = training_step(model, batch_images, batch_labels, loss_f)\n",
    "\n",
    "            if batch_i % 100 == 0:\n",
    "                print(f\"\\t{batch_i = }: {loss.numpy() = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data() \n",
    "\n",
    "#prep\n",
    "train_images = train_images.reshape((-1, 28 * 28))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "test_images = test_images.reshape((-1, 28 * 28))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "# get model\n",
    "model = NaiveSequential(\n",
    "    [\n",
    "        NaiveDense(28 * 28, 512, activation=tf.nn.relu),\n",
    "        NaiveDense(512, 10, activation=tf.nn.softmax),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0\n",
      "\tbatch_i = 0: loss.numpy() = 4.4671254\n",
      "\tbatch_i = 100: loss.numpy() = 2.2328553\n",
      "\tbatch_i = 200: loss.numpy() = 2.2252636\n",
      "\tbatch_i = 300: loss.numpy() = 2.107552\n",
      "\tbatch_i = 400: loss.numpy() = 2.210085\n",
      "epoch = 1\n",
      "\tbatch_i = 0: loss.numpy() = 1.9298022\n",
      "\tbatch_i = 100: loss.numpy() = 1.8736537\n",
      "\tbatch_i = 200: loss.numpy() = 1.8420581\n",
      "\tbatch_i = 300: loss.numpy() = 1.7289224\n",
      "\tbatch_i = 400: loss.numpy() = 1.8202466\n",
      "epoch = 2\n",
      "\tbatch_i = 0: loss.numpy() = 1.6024339\n",
      "\tbatch_i = 100: loss.numpy() = 1.5763326\n",
      "\tbatch_i = 200: loss.numpy() = 1.5169283\n",
      "\tbatch_i = 300: loss.numpy() = 1.4394305\n",
      "\tbatch_i = 400: loss.numpy() = 1.5089933\n",
      "epoch = 3\n",
      "\tbatch_i = 0: loss.numpy() = 1.3403506\n",
      "\tbatch_i = 100: loss.numpy() = 1.3415992\n",
      "\tbatch_i = 200: loss.numpy() = 1.2544831\n",
      "\tbatch_i = 300: loss.numpy() = 1.2256455\n",
      "\tbatch_i = 400: loss.numpy() = 1.2820411\n",
      "epoch = 4\n",
      "\tbatch_i = 0: loss.numpy() = 1.1394812\n",
      "\tbatch_i = 100: loss.numpy() = 1.1605272\n",
      "\tbatch_i = 200: loss.numpy() = 1.0601858\n",
      "\tbatch_i = 300: loss.numpy() = 1.0655044\n",
      "\tbatch_i = 400: loss.numpy() = 1.119645\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "fit(model, train_images, train_labels, epochs=5, loss_f=tf.losses.sparse_categorical_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7624\n"
     ]
    }
   ],
   "source": [
    "# evaluate our naive model\n",
    "\n",
    "predictions = model(test_images)\n",
    "predicted_labels = np.argmax(predictions.numpy(), axis=1)\n",
    "\n",
    "accuracy = (predicted_labels == test_labels).mean()\n",
    "print(f\"{accuracy = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
